# first_hw_bigdata_course_2025_FW
   Первое ДЗ по предмету BigData для потока БИВТ-22-СП | HDFS + MapReduce, Spark RDD, Spark DF API

# Домашнее Задание 1 : Работу необходимо выполнить на MR/HDFS, далее то же самое задание реализовать на Spark двумя способами (rdd + df api)

## Критерии оценивания (максимум 20 баллов):

до 8 баллов - работа корректно выполнена с использованием Map Reduce, получен адекватные резутальтат и есть базовое описание всех шагов (комментарии), есть выводы заданий в ноутбуке, применена работа с HDFS командами и прочее

до 6 баллов - работа выполнена с использованием Spark RDD, получен результат во всех заданиях, как и в первой реализации. Допустимы незначительные ошибки. Проведена сверка с решением на MR 

до 6 баллов - работа выполнена с использованием Spark DataFrame API, получен результат во всех заданиях, как и в предыдущих реализациях. Допустимы незначительные ошибки. Проведена сверка с двумя предшесвующими решениями.

Важно: выполнение задания №1 дает вам 4/3/3 балла при корректной реализации на соостветсвующем инструменте. Задание №2 также весит 4/3/3 балла соответственно. 

## Полезные ссылки:

- Книга о Hadoop (объяснение Map Reduce на странице 19) - [[Ссылка](https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-common/FileSystemShell.html)]
- Пример конфигурации для стадий перемешивания и сортировки в Map Reduce - [[Ссылка](https://hadoop.apache.org/docs/current/hadoop-streaming/HadoopStreaming.html#More_Usage_Examples)]
- Основные команды HDFS - [[Ссылка](https://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-common/FileSystemShell.html)]

## Задание 1:

Подсчитать количество слов в первом тексте с помощью фреймворка Map-Reduce:

1. В соответствующей ячейке реализовать код шага Map
2. В ячейке ниже реализовать код шага Reduce
3. Выполнить ячейку с bash-командой для локальной самопроверки
4. Запустить bash-скрипт для запуска MR-таска
5. Логи выполнения ячеек должны быть видимы
   
Важно: подсчитывайте число только тех слов, длина которых больше 4 символов.
Проводить процесс удаления знаков препинания и прочих символов не нужно!!!

## Задание 2:

Выведите топ-5 наиболее посещаемых сайтов за каждую из дат, представленных в файле "Посещения сайтов". Реализуйте код для этапов Map и Reduce. Кроме того, нужно сделать следующее:

1. Разместите это в ячейках с помощью магической функции %%writefile.
2. Напишите команду запуска MapReduce в отдельной ячейке, аналогичной заданию 2.1 (скопируйте и добавьте параметры конфигурации, если это необходимо).
3. Логи выполнения ячейки должны быть видимы.

Также рассмотрите обработку исключений при обработке звонков и сохранение в лог-файлах.

## Важное замечание:

Программы Map и Reduce должны работать с памятью сложности O (1), и если вы собираетесь создать список данных, то он не должен быть размера O (n).

## Формат сдачи

Необходимо отправить jupyter-ноутбук с кодом и логами выполнения ячейки. Вы также можете добавить дополнительные комментарии в сам блокнот.
Пожалуйста, убедитесь, что предоставленные ссылки работают и доступны для загрузки (если отправляете ссылку на диск, это приоритетный вариант)

К доке с заданием также приложен ноутбук с MapReduce и необходимые файлы с данными - это ваш шаблон для выполнения первой части домашнего задания. Во втром необходимо запустить спарк сессию для работы с данными. Мы предложим вам необходмую конфигурацию (без тюнинга параметров сессии) для того, чтобы была возможность верно стартануть спрак-сессию.

СП-1, СП-2, СП-3 (первые 16 человек по списку)
тг @bolyrevnow

СП-3 (вторые 16 человек по списку), СП-4, СП-5 
тг @bombomzhenya
